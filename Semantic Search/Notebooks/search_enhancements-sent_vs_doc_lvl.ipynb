{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to test the idea that sentence level embeddings can better detect similarity that document level embeddings.  The sentence level embeddings will be aggregated to document similarity, not by aggregating the embeddings themselves (that would defeat the purpose) but by aggregating the similarity scores between each document's similar sentences.\n",
    "\n",
    "This type of analysis introduces a new problem: sentence segmentation.  Flair's Syntok will be used for sentence segmentation, as the commonly used punkt from NLTK is dated and performs poorly.\n",
    "\n",
    "Example:\n",
    "\n",
    "In doc 1 and doc 2, sentences 1 and 2 were determined to be similar.  Doc 1 sent 1 matched with doc 2 sent 2, and doc 1 sent 2 matched with doc 2 sent 1.  Doc 1 had 10 total sentences and none of the other 8 matched with any other sentences from doc 2.\n",
    "\n",
    "Option 1: Average Sentence Lvl Score (similarity threshold = 0.2)\n",
    "\n",
    "| doc 1 | doc 2 | sentence similarity |\n",
    "| --- | --- | -- |\n",
    "| sent 1 | sent 2 | 0.83 |\n",
    "| sent 2 | sent 1 | 0.22 |\n",
    "| --- | --- | --- |\n",
    "| doc similarity | -- | 0.53 |\n",
    "\n",
    "Option 2: Number of Similar Sentences (similarity threshold = 0.2)\n",
    "\n",
    "| doc 1 | doc 2 | number sentences matched |\n",
    "| --- | --- | --- |\n",
    "| --- | --- | 2 |\n",
    "| doc similarity | --- | 2 |\n",
    "\n",
    "Of the 2 options, option 2 makes the most sense because it only involves setting 1 threshold: the one for sentence level similarity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import syntok.segmenter as segmenter\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from itertools import combinations_with_replacement\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.csgraph import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USEEmbeddingModel:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Universal Sentence Encoder (USE) is a state of the art semantic similarity model.\n",
    "        It is preferable to BERT embeddings for semantic similarity because:\n",
    "            * It was trained specifically for detecting semantic similarity with sentence pairs\n",
    "            * It has a greater range of values for the embedding dimensions than BERT, allowing it\n",
    "              to better separate close matches in the embedding space (0.5 - 0.8 vs 0.79 - 0.87 for BERT)\n",
    "        This class pulls the pre-trained USE model from TensorFlow Hub, then uses it to\n",
    "        create document level embeddings.  Note that USE has a dimensionality of 512, meaning\n",
    "        only the first 512 tokens of the document will be encoded.\n",
    "        \"\"\"\n",
    "        self.model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "        self.model = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        print(f\"Model {self.model_url} loading\")\n",
    "        self.model = hub.load(self.model_url)\n",
    "        print(f\"Model {self.model_url} loaded\")\n",
    "\n",
    "    @staticmethod\n",
    "    def batch(iterable, batch_size=1):\n",
    "        \"\"\"\n",
    "        Creates batches of equal size, batch_size\n",
    "\n",
    "        Example usage:\n",
    "            data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # list of data\n",
    "\n",
    "            for x in batch(data, 3):\n",
    "                print(x)\n",
    "\n",
    "            # Output\n",
    "\n",
    "            [0, 1, 2]\n",
    "            [3, 4, 5]\n",
    "            [6, 7, 8]\n",
    "            [9, 10]\n",
    "        \"\"\"\n",
    "        iterable_len = len(iterable)\n",
    "        for ndx in range(0, iterable_len, batch_size):\n",
    "            yield iterable[ndx:min(ndx + batch_size, iterable_len)]\n",
    "\n",
    "    def get_embeddings(self, text_input, batch_size=256):\n",
    "        \"\"\"\n",
    "        Runs text through the model and produces the embeddings\n",
    "\n",
    "        :param text_input: a list where each item is a document (a comment from this dataset)\n",
    "        :param batch_size: integer representing how many samples to include in a batch\n",
    "        \"\"\"\n",
    "        self._load_model()\n",
    "        embeddings = []\n",
    "        # helper variables to track progress\n",
    "        nbr_batches = int(np.ceil(len(text_input) / batch_size))\n",
    "        current_batch = 1\n",
    "\n",
    "        skipped = []  # these caused an error for whatever reason\n",
    "        for batch_indices in self.batch(iterable=range(len(text_input)), batch_size=batch_size):\n",
    "            progress = round(100 * current_batch / nbr_batches, 2)\n",
    "            if progress % 10 == 0:\n",
    "                print(f\"Embedding progress: {progress}%\")\n",
    "                print(progress)\n",
    "\n",
    "            # grab the records for this batch\n",
    "            batch_records = [text_input[idx] for idx in batch_indices]\n",
    "\n",
    "            try:\n",
    "                # forward pass over the input\n",
    "                model_output = self.model(batch_records)\n",
    "\n",
    "                # save the embeddings\n",
    "                embeddings.append(model_output.numpy())\n",
    "            \n",
    "            except:\n",
    "                skipped += batch_indices\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "        # convert the list of embeddings to a numpy array\n",
    "        embeddings = np.array(\n",
    "            [np.array(i) for i in np.vstack(embeddings).tolist()]\n",
    "        )\n",
    "\n",
    "        return embeddings, skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_to_sents(text: str):\n",
    "    sents = [sentence for paragraph in segmenter.analyze(text) for sentence in paragraph]\n",
    "    sents = [(''.join(str(t) for t in s).strip()) for s in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "news_df = pd.DataFrame({\"text\": news.data, \"topic\": news.target})\n",
    "news_df.dropna(subset=[\"text\"], axis=0, inplace=True)\n",
    "news_df = news_df.sample(frac=0.05)\n",
    "news_df = news_df.reset_index(drop=False).rename(columns={\"index\": \"doc_id\"})\n",
    "news_df['text'] = news_df['text'].apply(lambda x: re.sub(\"\\s+\", \" \", re.sub(\"\\t\", \" \", re.sub(\"\\n\", \" \", x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['text'] = news_df['text'].apply(parse_text_to_sents)\n",
    "news_df = news_df[news_df['text'].str.len() > 40]\n",
    "news_df = news_df.explode('text').reset_index(drop=True).reset_index(drop=False).rename(\n",
    "    columns={\"index\": \"global_id\"}\n",
    ")\n",
    "news_df['local_id'] = news_df.groupby(['doc_id'])['global_id'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 documents and 2208 sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(set(news_df.doc_id))} documents and {len(news_df)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>local_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4811</td>\n",
       "      <td>THE WHITE HOUSE Office of the Press Secretary (Pittsburgh, Pennslyvania) ______________________________________________________________ For Immediate Release April 17, 1993 RADIO ADDRESS TO THE NATION BY THE PRESIDENT Pittsburgh International Airport Pittsburgh, Pennsylvania 10:06 A.M. EDT THE PRESIDENT: Good morning.</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4811</td>\n",
       "      <td>My voice is coming to you this morning through the facilities of the oldest radio station in America, KDKA in Pittsburgh.</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4811</td>\n",
       "      <td>I'm visiting the city to meet personally with citizens here to discuss my plans for jobs, health care and the economy.</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4811</td>\n",
       "      <td>But I wanted first to do my weekly broadcast with the American people.</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4811</td>\n",
       "      <td>I'm told this station first broadcast in 1920 when it reported that year's presidential elections.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_id  doc_id  \\\n",
       "0          0    4811   \n",
       "1          1    4811   \n",
       "2          2    4811   \n",
       "3          3    4811   \n",
       "4          4    4811   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0  THE WHITE HOUSE Office of the Press Secretary (Pittsburgh, Pennslyvania) ______________________________________________________________ For Immediate Release April 17, 1993 RADIO ADDRESS TO THE NATION BY THE PRESIDENT Pittsburgh International Airport Pittsburgh, Pennsylvania 10:06 A.M. EDT THE PRESIDENT: Good morning.   \n",
       "1                                                                                                                                                                                                        My voice is coming to you this morning through the facilities of the oldest radio station in America, KDKA in Pittsburgh.   \n",
       "2                                                                                                                                                                                                           I'm visiting the city to meet personally with citizens here to discuss my plans for jobs, health care and the economy.   \n",
       "3                                                                                                                                                                                                                                                           But I wanted first to do my weekly broadcast with the American people.   \n",
       "4                                                                                                                                                                                                                               I'm told this station first broadcast in 1920 when it reported that year's presidential elections.   \n",
       "\n",
       "   topic  local_id  \n",
       "0     18         0  \n",
       "1     18         1  \n",
       "2     18         2  \n",
       "3     18         3  \n",
       "4     18         4  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Documents with USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model https://tfhub.dev/google/universal-sentence-encoder/4 loading\n",
      "Model https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n",
      "Embedding progress: 20.0%\n",
      "20.0\n",
      "Embedding progress: 40.0%\n",
      "40.0\n",
      "Embedding progress: 60.0%\n",
      "60.0\n",
      "Embedding progress: 80.0%\n",
      "80.0\n",
      "Embedding progress: 100.0%\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "model = USEEmbeddingModel()\n",
    "embeddings, skipped = model.get_embeddings(\n",
    "    text_input=news_df['text'].tolist(),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.drop(news_df.index[skipped], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(news_df) == embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build FAISS Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLIST = 100\n",
    "NPROBE = 10\n",
    "DISTANCE_THRESHOLD = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_embeddings, embed_dim = embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the L2 distance will be used as a quantizer for indices\n",
    "quantizer_use = faiss.IndexFlatL2(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 2208 points to 100 centroids: please provide at least 3900 training points\n"
     ]
    }
   ],
   "source": [
    "ivf_flat_index_use = faiss.IndexIVFFlat(quantizer_use, embed_dim, NLIST)\n",
    "ivf_flat_index_use.nprobe = NPROBE\n",
    "ivf_flat_index_use.train(embeddings.astype(np.float32))\n",
    "ivf_flat_index_use.add_with_ids(embeddings.astype(np.float32), news_df['global_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform range search for all document embeddings\n",
    "limits, distances, indices = ivf_flat_index_use.range_search(embeddings.astype(np.float32), DISTANCE_THRESHOLD)\n",
    "limits = limits.tolist()\n",
    "indices = indices.tolist()\n",
    "\n",
    "# form clusters by determining which documents are similar\n",
    "clusters = [indices[start:end] for start, end in zip(limits, limits[1:])]\n",
    "clusters = {i: set(v) for i, v in enumerate(clusters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not unique, broke on 0\n"
     ]
    }
   ],
   "source": [
    "# does any doc appear in more than 1 cluster?\n",
    "seen = []\n",
    "breaking_cluster = 0\n",
    "for k, v in clusters.items():\n",
    "    for d in v:\n",
    "        if d in seen:\n",
    "            breaking_cluster = k\n",
    "            break\n",
    "        else:\n",
    "            seen.append(d)\n",
    "    print(\"not unique, broke on\", breaking_cluster)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important, because it means that FAISS does not assign to unique clusters.  Connected components is required if a doc can only have 1 cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2208"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])\n",
    "\n",
    "# create a square adjacency matrix from the edge list\n",
    "nbr_documents = embeddings.shape[0]\n",
    "matrix_shape = (nbr_documents, nbr_documents)\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# determine cluster assignment by document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637 2208\n"
     ]
    }
   ],
   "source": [
    "print(nbr_clusters, len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_id_to_global_id_map = {k: v for k, v in enumerate(news_df['global_id'].tolist())}\n",
    "global_id_to_cluster_map = dict(zip(faiss_id_to_global_id_map, cluster))\n",
    "news_df['cluster'] = news_df['global_id'].map(global_id_to_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>local_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4811</td>\n",
       "      <td>THE WHITE HOUSE Office of the Press Secretary (Pittsburgh, Pennslyvania) ______________________________________________________________ For Immediate Release April 17, 1993 RADIO ADDRESS TO THE NATION BY THE PRESIDENT Pittsburgh International Airport Pittsburgh, Pennsylvania 10:06 A.M. EDT THE PRESIDENT: Good morning.</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4811</td>\n",
       "      <td>My voice is coming to you this morning through the facilities of the oldest radio station in America, KDKA in Pittsburgh.</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4811</td>\n",
       "      <td>I'm visiting the city to meet personally with citizens here to discuss my plans for jobs, health care and the economy.</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4811</td>\n",
       "      <td>But I wanted first to do my weekly broadcast with the American people.</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4811</td>\n",
       "      <td>I'm told this station first broadcast in 1920 when it reported that year's presidential elections.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_id  doc_id  \\\n",
       "0          0    4811   \n",
       "1          1    4811   \n",
       "2          2    4811   \n",
       "3          3    4811   \n",
       "4          4    4811   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0  THE WHITE HOUSE Office of the Press Secretary (Pittsburgh, Pennslyvania) ______________________________________________________________ For Immediate Release April 17, 1993 RADIO ADDRESS TO THE NATION BY THE PRESIDENT Pittsburgh International Airport Pittsburgh, Pennsylvania 10:06 A.M. EDT THE PRESIDENT: Good morning.   \n",
       "1                                                                                                                                                                                                        My voice is coming to you this morning through the facilities of the oldest radio station in America, KDKA in Pittsburgh.   \n",
       "2                                                                                                                                                                                                           I'm visiting the city to meet personally with citizens here to discuss my plans for jobs, health care and the economy.   \n",
       "3                                                                                                                                                                                                                                                           But I wanted first to do my weekly broadcast with the American people.   \n",
       "4                                                                                                                                                                                                                               I'm told this station first broadcast in 1920 when it reported that year's presidential elections.   \n",
       "\n",
       "   topic  local_id  cluster  \n",
       "0     18         0        0  \n",
       "1     18         1        1  \n",
       "2     18         2        2  \n",
       "3     18         3        3  \n",
       "4     18         4        4  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of shared sentences between documents as proportion of total sentences\n",
    "doc_ids = set(news_df['doc_id'])\n",
    "doc_similarity = {}\n",
    "for doc1 in doc_ids:\n",
    "    for doc2 in doc_ids:\n",
    "        if doc1 == doc2:\n",
    "            next\n",
    "        doc1_c = news_df[news_df['doc_id'] == doc1].groupby('cluster')['global_id'].count().reset_index()\n",
    "        doc2_c = news_df[news_df['doc_id'] == doc2].groupby('cluster')['global_id'].count().reset_index()\n",
    "        both = pd.merge(doc1_c, doc2_c, on='cluster', how='inner')\n",
    "        if len(both) != 0:\n",
    "            both['shared'] = both.apply(lambda x: min(x['global_id_x'], x['global_id_y']), axis=1)\n",
    "            perc_shared = both['shared'].sum() / len(news_df[news_df['doc_id'] == doc1])\n",
    "        else:\n",
    "            perc_shared = 0\n",
    "        doc_similarity[str(doc1) + \"_\" + str(doc2)] = perc_shared\n",
    "doc_similarity = pd.DataFrame.from_dict(doc_similarity, orient='index').reset_index(drop=False)\n",
    "doc_similarity = pd.concat([doc_similarity, doc_similarity['index'].str.split(\"_\", expand=True)], axis=1)\n",
    "doc_similarity.columns = [\"index\", \"perc_similar\", \"doc_id1\", \"doc_id2\"]\n",
    "doc_similarity.drop(\"index\", axis=1, inplace=True)\n",
    "doc_similarity = doc_similarity[doc_similarity['doc_id1'] != doc_similarity['doc_id2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_similar</th>\n",
       "      <th>doc_id1</th>\n",
       "      <th>doc_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>2275</td>\n",
       "      <td>7972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>2275</td>\n",
       "      <td>6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>2275</td>\n",
       "      <td>1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.190476</td>\n",
       "      <td>2275</td>\n",
       "      <td>9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>2275</td>\n",
       "      <td>5447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perc_similar doc_id1 doc_id2\n",
       "1      0.333333    2275    7972\n",
       "2      0.333333    2275    6950\n",
       "3      0.380952    2275    1511\n",
       "4      0.190476    2275    9094\n",
       "5      0.333333    2275    5447"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_similarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc_similar</th>\n",
       "      <th>doc_id1</th>\n",
       "      <th>doc_id2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.729032</td>\n",
       "      <td>7972</td>\n",
       "      <td>4682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.735484</td>\n",
       "      <td>7972</td>\n",
       "      <td>6151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.773481</td>\n",
       "      <td>6950</td>\n",
       "      <td>7972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.745856</td>\n",
       "      <td>6950</td>\n",
       "      <td>5447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.762431</td>\n",
       "      <td>6950</td>\n",
       "      <td>4682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    perc_similar doc_id1 doc_id2\n",
       "23      0.729032    7972    4682\n",
       "25      0.735484    7972    6151\n",
       "35      0.773481    6950    7972\n",
       "39      0.745856    6950    5447\n",
       "40      0.762431    6950    4682"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_similarity[doc_similarity['perc_similar'] > 0.5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>local_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>4682</td>\n",
       "      <td>Archive-name: net-privacy/part2 Last-modified: 1993/3/3 Version: 2.1 IDENTITY, PRIVACY, and ANONYMITY on the INTERNET ================================================ (c) 1993 L. Detweiler.</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>4682</td>\n",
       "      <td>Not for commercial use except by permission from author, otherwise may be freely copied.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>4682</td>\n",
       "      <td>Not to be altered.</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>4682</td>\n",
       "      <td>Please credit if quoted.</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>4682</td>\n",
       "      <td>SUMMARY ======= Email and account privacy, anonymity, file encryption, academic computer policies, relevant legislation and references, EFF, and other privacy and rights issues associated with use of the Internet and global networks in general.</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>6151</td>\n",
       "      <td>Source and binaries for HP-UX 8.*/9.0(S300/400/700/800) and Domain 10.4 (68K, DN 10K) are available through the Interworks Users Group; contact Carol Relph at 508-436-5046, fax 508-256-7169, or relph_c@apollo.hp.com. Patches to X11R5 for Solaris 2.1 by Casper H.S. Dik (casper@fwi.uva.nl) et al are on export in contrib/{R5.SunOS5.patch.tar.Z,R5.SunOS5.patch.README}.</td>\n",
       "      <td>5</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>6151</td>\n",
       "      <td>Patches to X11R5 for the Sun Type 5 keyboard and the keyboard NumLock are available from William Bailey (dbgwab@arco.com).</td>\n",
       "      <td>5</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>6151</td>\n",
       "      <td>Also: Binaries are available from Unipalm (+44 954 211797, xtech@unipalm.co.uk), probably for the Sun platforms.</td>\n",
       "      <td>5</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>6151</td>\n",
       "      <td>---------------------------------------------------------------------- David B. Lewis faq%craft@uunet.uu.net \"Just the FAQs, ma'am.\"</td>\n",
       "      <td>5</td>\n",
       "      <td>284</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>6151</td>\n",
       "      <td>-- Joe Friday</td>\n",
       "      <td>5</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      global_id  doc_id  \\\n",
       "64           64    4682   \n",
       "65           65    4682   \n",
       "66           66    4682   \n",
       "67           67    4682   \n",
       "68           68    4682   \n",
       "...         ...     ...   \n",
       "2156       2156    6151   \n",
       "2157       2157    6151   \n",
       "2158       2158    6151   \n",
       "2159       2159    6151   \n",
       "2160       2160    6151   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "64                                                                                                                                                                                      Archive-name: net-privacy/part2 Last-modified: 1993/3/3 Version: 2.1 IDENTITY, PRIVACY, and ANONYMITY on the INTERNET ================================================ (c) 1993 L. Detweiler.   \n",
       "65                                                                                                                                                                                                                                                                                           Not for commercial use except by permission from author, otherwise may be freely copied.   \n",
       "66                                                                                                                                                                                                                                                                                                                                                                 Not to be altered.   \n",
       "67                                                                                                                                                                                                                                                                                                                                                           Please credit if quoted.   \n",
       "68                                                                                                                               SUMMARY ======= Email and account privacy, anonymity, file encryption, academic computer policies, relevant legislation and references, EFF, and other privacy and rights issues associated with use of the Internet and global networks in general.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "2156  Source and binaries for HP-UX 8.*/9.0(S300/400/700/800) and Domain 10.4 (68K, DN 10K) are available through the Interworks Users Group; contact Carol Relph at 508-436-5046, fax 508-256-7169, or relph_c@apollo.hp.com. Patches to X11R5 for Solaris 2.1 by Casper H.S. Dik (casper@fwi.uva.nl) et al are on export in contrib/{R5.SunOS5.patch.tar.Z,R5.SunOS5.patch.README}.   \n",
       "2157                                                                                                                                                                                                                                                       Patches to X11R5 for the Sun Type 5 keyboard and the keyboard NumLock are available from William Bailey (dbgwab@arco.com).   \n",
       "2158                                                                                                                                                                                                                                                                 Also: Binaries are available from Unipalm (+44 954 211797, xtech@unipalm.co.uk), probably for the Sun platforms.   \n",
       "2159                                                                                                                                                                                                                                             ---------------------------------------------------------------------- David B. Lewis faq%craft@uunet.uu.net \"Just the FAQs, ma'am.\"   \n",
       "2160                                                                                                                                                                                                                                                                                                                                                                    -- Joe Friday   \n",
       "\n",
       "      topic  local_id  cluster  \n",
       "64       11         0        2  \n",
       "65       11         1        2  \n",
       "66       11         2        2  \n",
       "67       11         3       28  \n",
       "68       11         4        2  \n",
       "...     ...       ...      ...  \n",
       "2156      5       281        2  \n",
       "2157      5       282        2  \n",
       "2158      5       283        2  \n",
       "2159      5       284      331  \n",
       "2160      5       285        2  \n",
       "\n",
       "[1047 rows x 6 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df[news_df['doc_id'].isin([7972, 4682, 6151])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These documents do not look too similar.  It seems there are many short sentences that could be noise.  \n",
    "\n",
    "After removing short sentences < 40 characters, the documents still do not look very similar.  It seems that sentence level comparisons are not good for judging document level similarity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
